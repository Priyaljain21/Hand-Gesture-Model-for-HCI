# Hand Gesture Model for Human-Computer Interaction (HCI)

## Overview
This project implements a **Hand Gesture Recognition Model** using **OpenCV, MediaPipe, and PyAutoGUI** to control a computer's cursor through real-time hand movements. The model tracks hand movements via a webcam and translates gestures as well.

## Features
- **Hand Tracking**: Uses MediaPipe for real-time hand landmark detection.
- **Gesture Recognition**: Detects and classifies various hand gestures.
- **Mouse Control**: Enables cursor movement, clicks, and drags using hand movements.
- **Real-time Processing**: Efficient and lightweight implementation for smooth interaction.

## Technologies Used
- **Python**
- **OpenCV** (Computer Vision processing)
- **MediaPipe** (Hand tracking and gesture detection)
- **PyAutoGUI** (Simulating mouse control)

## Usage
- Move the cursor by moving your hand.
- Pinch with index and thumb to simulate a click.
- Use other gestures e.g., thumbs up, fist etc.

## Future Enhancements
- Add gesture-based keyboard controls.
- Improve accuracy for complex gestures.
- Integrate voice commands for hybrid interaction.
